# .github/workflows/deploy.yml
name: Deploy VinylPlatz to GCP (Public SQL IP)

on:
  push:
    branches:
      - main # Trigger deployment on push to the main branch

# Permissions required by the Google Cloud GitHub Actions
permissions:
  contents: 'read'   # Allows checking out the repository
  id-token: 'write'  # Allows authenticating to Google Cloud via OIDC/SA Key

env:
  NODE_VERSION: '20.x' # Specify Node.js version
  # Read secrets defined in GitHub repository settings
  GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  GCP_ARTIFACT_REGISTRY_REPO: ${{ secrets.GCP_ARTIFACT_REGISTRY_REPO }}
  GCP_CLOUD_RUN_SERVICE_NAME: ${{ secrets.GCP_CLOUD_RUN_SERVICE_NAME }}
  GCP_CLOUD_RUN_REGION: ${{ secrets.GCP_CLOUD_RUN_REGION }}
  GCP_STORAGE_BUCKET_NAME: ${{ secrets.GCP_STORAGE_BUCKET_NAME }} # Should be like gs://your-bucket
  # Consistent name for the Docker image being built/pushed
  BACKEND_IMAGE_NAME: vinylplatz-backend

jobs:
  build_and_deploy:
    name: Build & Deploy to GCP # Name of the job
    runs-on: ubuntu-latest      # Use the latest Ubuntu runner provided by GitHub
    environment: production     # Optional: Link to a GitHub Environment

    steps:
    # --- Setup Steps ---
    - name: Checkout code
      uses: actions/checkout@v4 # Checks out your repository code

    - name: Set up Node.js
      uses: actions/setup-node@v4 # Sets up the specified Node.js version
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm' # Enable caching for npm dependencies
        # Use relative path from workspace root for cache key consistency in runner
        cache-dependency-path: ./package-lock.json

    - name: Install dependencies
      # Run npm ci from the workspace root. Use --force to potentially bypass peer dependency issues.
      run: npm ci --force
      working-directory: ./ # Relative path from checkout root

    - name: Authenticate to Google Cloud
      id: auth # Give this step an ID to reference later if needed
      uses: 'google-github-actions/auth@v2' # Google's official action for authentication
      with:
        # Use the base64 encoded service account key stored as a secret
        credentials_json: ${{ secrets.GCP_SA_KEY }}

    - name: Set up Cloud SDK (gcloud)
      uses: 'google-github-actions/setup-gcloud@v2' # Installs and configures the gcloud CLI

    # --- Optional Debugging Step (can be removed later) ---
    - name: List files in build context
      run: |
        echo "Listing files from repository root:"
        ls -laR ./
      working-directory: ./ # Run from the checkout root

    # --- Backend Build & Deploy (Cloud Run) ---
    - name: Extract Artifact Registry Hostname
      id: get_registry_host # Give this step an ID
      # Use shell command to extract the part before the first '/'
      run: echo "hostname=$(echo $GCP_ARTIFACT_REGISTRY_REPO | cut -d'/' -f1)" >> $GITHUB_OUTPUT
      env:
        GCP_ARTIFACT_REGISTRY_REPO: ${{ env.GCP_ARTIFACT_REGISTRY_REPO }}

    - name: Configure Docker for Artifact Registry
      # Authenticates Docker CLI with the extracted hostname
      run: gcloud auth configure-docker ${{ steps.get_registry_host.outputs.hostname }} --quiet

    - name: Set up Docker Buildx
      # Initializes Docker Buildx for enhanced build capabilities (like caching)
      uses: docker/setup-buildx-action@v3

    - name: Build and Push Backend Docker Image
      id: docker_build # Give this step an ID to reference its outputs
      uses: docker/build-push-action@v5 # Action to build and push Docker images
      with:
        context: ./ # Build context is the workspace root
        file: ./apps/data-api/Dockerfile # Relative path to the Dockerfile
        push: true # Push the built image to the registry
        # Tag the image with the full registry path and the unique commit SHA
        tags: ${{ env.GCP_ARTIFACT_REGISTRY_REPO }}/${{ env.BACKEND_IMAGE_NAME }}:${{ github.sha }}
        cache-from: type=gha # Use GitHub Actions cache for Docker layers
        cache-to: type=gha,mode=max # Write cache layers back to GHA cache

    - name: Deploy Backend to Cloud Run
      id: deploy_backend # Give this step an ID to reference its outputs
      uses: 'google-github-actions/deploy-cloudrun@v2' # Action to deploy to Cloud Run
      with:
        service: ${{ env.GCP_CLOUD_RUN_SERVICE_NAME }} # Target Cloud Run service name
        region: ${{ env.GCP_CLOUD_RUN_REGION }}       # Target Cloud Run region
        # *** FIX: Use the full image tag (including registry) instead of just the digest ***
        image: ${{ env.GCP_ARTIFACT_REGISTRY_REPO }}/${{ env.BACKEND_IMAGE_NAME }}:${{ github.sha }}
        # Pass runtime environment variables (read from GitHub Secrets)
        env_vars: |
          NODE_ENV=production
          DATABASE_URL=${{ secrets.DATABASE_URL }}
          JWT_SECRET=${{ secrets.JWT_SECRET }}

    # --- Frontend Build & Deploy (Cloud Storage) ---
    - name: Build Vue frontend
      # Run the Nx build command for the frontend app in production mode
      run: npx nx build vinylplatz-web --configuration=production
      working-directory: ./ # Ensure command runs from workspace root
      env:
        # Critical: Set the VITE_API_URL environment variable during the build
        # This injects the *actual deployed backend URL* into the frontend code
        # Assumes your NestJS global prefix is /api. Adjust if different.
        VITE_API_URL: ${{ steps.deploy_backend.outputs.url }}/api

    - name: Extract GCS Bucket Name (without gs://)
      id: get_bucket_name # Give this step an ID
      # Use shell command to remove the 'gs://' prefix
      run: echo "name=$(echo $GCP_STORAGE_BUCKET_NAME | sed 's#gs://##')" >> $GITHUB_OUTPUT
      env:
        GCP_STORAGE_BUCKET_NAME: ${{ env.GCP_STORAGE_BUCKET_NAME }}

    - name: Deploy Frontend to Google Cloud Storage
      uses: 'google-github-actions/upload-cloud-storage@v2' # Action to upload files to GCS
      with:
        # Path to the built frontend artifacts within the runner's workspace
        path: ./dist/apps/vinylplatz-web
        # Target GCS bucket name (extracted in the previous step)
        destination: ${{ steps.get_bucket_name.outputs.name }}
        # Upload contents directly into the bucket, not within a parent folder
        parent: false
        # Optional: Set cache headers for uploaded files
        headers: |
          cache-control: public, max-age=3600